{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "// By default Synapse uses AAD passthrough for authentication\n",
        "// TokenLibrary is invoked under the hood for obtaining AAD token and using it for\n",
        "// authenticating against the resource\n",
        "\n",
        "val df = spark.read.parquet(\"abfss://..\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "// While Gen2 is the default storage for Synapse, AAD passthrough support exists for Gen1 as well. PLEASE NOTE THAT WE DO NOT OFFICIALLY SUPPORT GEN1 IN SYNAPSE AND CUSTOMERS WHO USE IT ARE ON THEIR OWN.\n",
        "\n",
        "val df = spark.read.parquet(\"adl://\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "// Linked services can be used for storing and retreiving credentials (e.g, account key)\n",
        "// Example connection string (for storage): \"DefaultEndpointsProtocol=https;AccountName=<accountname>;AccountKey=<accountkey>\"\n",
        "\n",
        "val connectionString: String = TokenLibrary.getConnectionString(\"<linkedServiceName>\")\n",
        "val accountKey: String = TokenLibrary.getConnectionStringAsMap(\"<linkedServiceName>\").get(\"AccountKey\")\n",
        ""
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "// The following feature is in the works. Synapse will have inbuilt integration of linked services with storage Gen2 via TokenLibrary\n",
        "// For storage Gen2, linkedServiceName can be supplied through config for SAS-key based authentication (in lieu of account-key based authentication) \n",
        "// Direct invokation of TokenLibrary is not required for obtaining creds and connection info\n",
        "\n",
        "val sc = spark.sparkContext\n",
        "sc.hadoopConfiguration.set(\"spark.storage.synapse.linkedServiceName\", \"<linkedServiceName>\")\n",
        "sc.hadoopConfiguration.set(\"fs.azure.account.auth.type\", \"SAS\")\n",
        "sc.hadoopConfiguration.set(\"fs.azure.sas.token.provider.type\", \"com.microsoft.azure.synapse.tokenlibrary.LinkedServiceBasedSASProvider\")\n",
        "\n",
        "val df = spark.read.parquet(\"abfss://..\")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        ""
      ],
      "attachments": {}
    }
  ]
}
